Parameters:
{'state_length': 2.0, 'metric': 'cityblock', 'window': 'tukey', 'window_param': 0.25, 'overlap': 0.125, 'log_frequency': True}


================================================================================
Layer
================================================================================
Data: data
Models:
reduced_model: `log(normalized differentiation)` ~ 1 + layer + stimulus_type + 
reduced_model:     (1 | session)
model: `log(normalized differentiation)` ~ 1 + layer * stimulus_type + 
model:     (1 | session)
              Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
reduced_model  6 1537.1 1571.2 -762.53   1525.1                             
model          8 1526.9 1572.4 -755.43   1510.9 14.205      2  0.0008232 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	 Simultaneous Tests for General Linear Hypotheses

Fit: lmer(formula = `log(normalized differentiation)` ~ 1 + layer * 
    stimulus_type + (1 | session), data = data, REML = FALSE)

Linear Hypotheses:
                                    Estimate Std. Error z value   Pr(>z)    
L2/3:natural - L2/3:artificial <= 0  0.09016    0.02437   3.699 0.000324 ***
L4:natural - L4:artificial <= 0      0.01339    0.02437   0.549 0.644202    
L5:natural - L5:artificial <= 0     -0.04135    0.02523  -1.639 0.999870    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Adjusted p values reported -- single-step method)


	 Simultaneous Confidence Intervals

Fit: lmer(formula = `log(normalized differentiation)` ~ 1 + layer * 
    stimulus_type + (1 | session), data = data, REML = FALSE)

Quantile = -2.1211
95% family-wise confidence level
 

Linear Hypotheses:
                                    Estimate lwr      upr     
L2/3:natural - L2/3:artificial <= 0  0.09016  0.03847      Inf
L4:natural - L4:artificial <= 0      0.01339 -0.03831      Inf
L5:natural - L5:artificial <= 0     -0.04135 -0.09486      Inf


================================================================================
Area
================================================================================
Data: data
Models:
reduced_model: `log(normalized differentiation)` ~ 1 + area + stimulus_type + 
reduced_model:     (1 | session)
model: `log(normalized differentiation)` ~ 1 + area * stimulus_type + 
model:     (1 | session)
              Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)   
reduced_model  8 1543.2 1588.7 -763.58   1527.2                            
model         12 1534.4 1602.8 -755.20   1510.4 16.771      4   0.002141 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	 Simultaneous Tests for General Linear Hypotheses

Fit: lmer(formula = `log(normalized differentiation)` ~ 1 + area * 
    stimulus_type + (1 | session), data = data, REML = FALSE)

Linear Hypotheses:
                                Estimate Std. Error z value  Pr(>z)   
V1:natural - V1:artificial <= 0  0.02868    0.03145   0.912 0.63117   
LM:natural - LM:artificial <= 0 -0.01908    0.03145  -0.607 0.99851   
AL:natural - AL:artificial <= 0  0.09859    0.03335   2.956 0.00777 **
PM:natural - PM:artificial <= 0 -0.06216    0.03145  -1.977 1.00000   
AM:natural - AM:artificial <= 0  0.07319    0.03145   2.327 0.04888 * 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Adjusted p values reported -- single-step method)


	 Simultaneous Confidence Intervals

Fit: lmer(formula = `log(normalized differentiation)` ~ 1 + area * 
    stimulus_type + (1 | session), data = data, REML = FALSE)

Quantile = -2.319
95% family-wise confidence level
 

Linear Hypotheses:
                                Estimate   lwr        upr       
V1:natural - V1:artificial <= 0  0.0286837 -0.0442390        Inf
LM:natural - LM:artificial <= 0 -0.0190820 -0.0920046        Inf
AL:natural - AL:artificial <= 0  0.0985918  0.0212457        Inf
PM:natural - PM:artificial <= 0 -0.0621582 -0.1350808        Inf
AM:natural - AM:artificial <= 0  0.0731880  0.0002654        Inf




~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


